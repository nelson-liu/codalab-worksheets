import argparse
import logging
import uuid
import subprocess
import getpass
from pathlib import Path
import random
import re

from .worker_manager import WorkerManager, WorkerJob

logger = logging.getLogger(__name__)


class SlurmBatchWorkerManager(WorkerManager):
    NAME = 'slurm-batch'
    DESCRIPTION = 'Worker manager for submitting jobs using Slurm Batch'

    SRUN_COMMAND = 'srun'
    SBATCH_COMMAND = 'sbatch'
    SBATCH_PREFIX = '#SBATCH'
    SQUEUE_COMMAND = 'squeue'
    SBATCH_COMMAND_RETRUN_REGEX = re.compile(r'^Submitted batch job (\d+)$')

    @staticmethod
    def add_arguments_to_subparser(subparser):
        subparser.add_argument(
            '--job-name',
            type=str,
            default='codalab-slurm-worker',
            help='Name for the job that will be generated by this worker manager',
        )
        subparser.add_argument(
            '--nodelist', type=str, default='', help='The worker node to run jobs in'
        )
        subparser.add_argument(
            '--partition', type=str, default='jag-standard', help='Name of batch job queue to use'
        )
        subparser.add_argument(
            '--cpus', type=int, default=1, help='Default number of CPUs for each worker'
        )
        subparser.add_argument(
            '--gpus', type=int, default=1, help='Default number of GPUs for each worker'
        )
        subparser.add_argument(
            '--memory-mb', type=int, default=2048, help='Default memory (in MB) for each worker'
        )
        subparser.add_argument(
            '--dry-run',
            action='store_true',
            help='Print out Slurm batch job definition without submitting to Slurm',
        )
        subparser.add_argument(
            '--user', type=str, default=getpass.getuser(), help='User to run the Batch jobs as'
        )
        subparser.add_argument(
            '--password-file',
            type=str,
            required=True,
            help='Path to the file containing the username and '
            'password for logging into the CodaLab worker '
            'each on a separate line. If not specified, the '
            'the worker will fail to start',
        )
        subparser.add_argument(
            '--work-dir',
            default='slurm-worker-scratch',
            help='Directory where to store temporary bundle data, '
            'including dependencies and the data from run bundles',
        )

    def __init__(self, args):
        super().__init__(args)
        self.username = self.args.user
        # A set of newly submitted job id to keep tracking worker status, as worker might not be created right away.
        self.submitted_jobs = self.load_worker_jobs()

    def load_worker_jobs(self):
        """
        Load worker jobs that are created using SlurmWorkerManager and
        owned by the current user from the Slurm scheduling queue.
        :return: a set of job id
        """
        # Get all the Slurm workers that are submitted by SlurmWorkerManager and owned by the current user.
        # Returning result will be in the following format:
        # JOBID:STATE (header won't be included with "--noheader" option)
        # 1487896,john-job-3157358
        # 1478830,john-job-5234492
        submitted_jobs = set()
        jobs = self.run_command(['squeue', '-u', self.username, '--format', '%A,%j', '--noheader'])
        for job in jobs.strip().split():
            job_id, job_name = job.split(',')
            if job_name.startswith(self.username) and self.args.job_name in job_name:
                submitted_jobs.add(job_id)
        return submitted_jobs

    def get_worker_jobs(self):
        """
        Return a list of workers in RUNNING and PENDING state.
        The current Slurm version on NLP cluster is 17.11.13-2, which doesn't have rest api provided.
        """
        # Documentation can be found at https://slurm.schedmd.com
        # Since allocating resource for a worker may take a while, we periodically check
        # for worker status and remove those workers that failed at starting phase.
        jobs_to_remove = set()
        for job_id in self.submitted_jobs:
            job_acct = self.run_command(['sacct', '-j', job_id, '--format', 'state'])
            if 'FAILED' in job_acct:
                jobs_to_remove.add(job_id)
                logger.error("Failed to start job {}".format(job_id))
            elif 'COMPLETING' in job_acct or 'COMPLETED' in job_acct or 'CANCELLED' in job_acct:
                jobs_to_remove.add(job_id)
        self.submitted_jobs = self.submitted_jobs - jobs_to_remove
        logger.info("Submitted jobs: ".format(self.submitted_jobs))

        # Get all the Slurm workers that are submitted by SlurmWorkerManager and owned by the current user.
        # Returning result will be in the following format:
        # JOBID:STATE (header won't be included with "--noheader" option)
        # 1478828,PENDING
        # 1478830,PENDING
        jobs = self.run_command(['squeue', '-u', self.username, '--format', '%A,%T', '--noheader'])
        jobs = jobs.strip().split()
        logger.info(
            'Workers: {}'.format(
                ' '.join(job for job in jobs if job in self.submitted_jobs) or '(none)'
            )
        )

        # Get all the RUNNING jobs that are owned by the current user.
        # Returning result will be in the following format:
        # JOBID (header won't be included with "--noheader" option)
        # 1478828
        # 1478830
        running_jobs = self.run_command(
            ['squeue', '-u', self.username, '-t', 'RUNNING', '--format', '%A', '--noheader']
        )
        running_jobs = running_jobs.strip().split()

        return [
            WorkerJob(active=True) if job in running_jobs else WorkerJob(active=False)
            for job in self.submitted_jobs
        ]

    def start_worker_job(self):
        """
        Start a CodaLab Slurm worker that submits batch job to Slurm
        """
        worker_id = uuid.uuid4().hex
        # Set up worker directory
        work_dir = Path(self.args.work_dir, worker_id)
        work_dir.mkdir(parents=True, exist_ok=True)

        # This needs to be a unique directory since Batch jobs may share a host
        worker_network_prefix = 'cl_worker_{}_network'.format(worker_id)
        command = [
            'cl-worker',
            '--server',
            self.args.server,
            '--verbose',
            '--exit-when-idle',
            '--idle-seconds',
            str(self.args.worker_idle_seconds),
            '--work-dir',
            str(work_dir),
            '--id',
            worker_id,
            '--network-prefix',
            worker_network_prefix,
            # always set in Slurm worker manager to ensure safe shutdown
            '--pass-down-termination',
            '--password-file',
            self.args.password_file,
        ]
        if self.args.worker_tag:
            command.extend(['--tag', self.args.worker_tag])

        slurm_args = self.create_slurm_args(self.args)
        job_definition = self.create_job_definition(slurm_args=slurm_args, command=command)

        # Not submit job to Slurm if dry runÂ is specified
        if self.args.dry_run:
            return

        batch_script = str(work_dir.joinpath(slurm_args['job-name'] + '.slurm'))
        self.save_job_definition(batch_script, job_definition)
        job_id_str = self.run_command([self.SBATCH_COMMAND, batch_script])

        match = re.match(self.SBATCH_COMMAND_RETRUN_REGEX, job_id_str)
        if match is not None:
            job_id = match.group(1)
        else:
            logger.error("Cannot find job_id in {}.".format(job_id_str))
            return

        # Add the newly submitted job to submitted_jobs for tracking purpose
        self.submitted_jobs.add(job_id)

    def run_command(self, command):
        proc = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        output, errors = proc.communicate()
        if output:
            logger.info("Executed command: {}".format(' '.join(command)))
            return output.decode()
        if errors:
            print("Failed to execute {}: {}: {}".format(' '.join(command), errors, proc.returncode))
            logger.error(errors)
        return ""

    def save_job_definition(self, job_file, job_definition):
        """
        Save the batch job definition to file.
        :param job_file: a file storing the Slurm batch job configuration
        :param job_definition: the job definition of a Slurm batch job
        :return:
        """
        with open(job_file, 'w') as f:
            f.write(job_definition)
        logger.info("Saved the Slurm Batch Job Definition to {}".format(job_file))

    def create_job_definition(self, slurm_args, command):
        """
        Create a Slurm batch job definition structured as a list of Slurm batch arguments and a srun command
        :param slurm_args: arguments for launching a Slurm batch job
        :param command: arguments for starting a CodaLab worker
        :return: a string containing the Slurm batch job definition
        """
        sbatch_args = [
            '{} --{}={}'.format(self.SBATCH_PREFIX, key, slurm_args[key])
            for key in sorted(slurm_args.keys())
        ]
        # Using the --unbuffered option with srun command will allow output
        # appear in the output file as soon as it is produced.
        srun_args = [self.SRUN_COMMAND, '--unbuffered'] + command
        # job definition contains two sections: sbatch arguments and srun command
        job_definition = '#!/bin/bash\n\n' + '\n'.join(sbatch_args) + '\n\n' + ' '.join(srun_args)
        print("Slurm Batch Job Definition")
        print(job_definition)
        return job_definition

    def create_random_job_name(self, job_name):
        """
        Generate a random Slurm job name
        :param job_name:
        :return: slurm job name
        """
        return self.username + "-" + job_name + '-' + str(random.randint(0, 5000000))

    def create_slurm_args(self, args):
        """
        Convert command line arguments to Slurm
        :param args: command line arguments
        :return: a dictionary of Slurm arguments
        """
        slurm_args = {}
        slurm_args['nodelist'] = self.args.nodelist
        slurm_args['mem'] = self.args.memory_mb
        slurm_args['partition'] = self.args.partition
        slurm_args['gres'] = "gpu:" + str(self.args.gpus)
        # job-name is unique
        slurm_args['job-name'] = self.create_random_job_name(self.args.job_name)
        slurm_args['cpus-per-task'] = str(self.args.cpus)
        slurm_args['ntasks-per-node'] = 1
        slurm_args['time'] = '10-0'
        slurm_args['open-mode'] = 'append'
        slurm_args['output'] = slurm_args['job-name'] + '.out'
        return slurm_args
